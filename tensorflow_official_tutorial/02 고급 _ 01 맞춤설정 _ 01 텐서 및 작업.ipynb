{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNqQAxOxQl3gAVe1uSXH5m/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9fG-ptArl8J","executionInfo":{"status":"ok","timestamp":1736840792692,"user_tz":-540,"elapsed":398,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"0b99e677-e4f9-4fd3-f208-09caff7f9170"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== 연산 ==========\n","\n","tf.Tensor(3, shape=(), dtype=int32)\n","tf.Tensor([4 6], shape=(2,), dtype=int32)\n","tf.Tensor(25, shape=(), dtype=int32)\n","tf.Tensor(6, shape=(), dtype=int32)\n","tf.Tensor(13, shape=(), dtype=int32)\n","\n","========== 크기와 데이터 타입 ==========\n","\n","tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n","(1, 2)\n","<dtype: 'int32'>\n","\n","========== Tensor와 NumPy의 호환성 ==========\n","\n","TensorFlow operations convert numpy arrays to Tensors automatically\n","tf.Tensor(\n","[[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]], shape=(3, 3), dtype=float64)\n","And NumPy operations convert Tensors to NumPy arrays automatically\n","[[43. 43. 43.]\n"," [43. 43. 43.]\n"," [43. 43. 43.]]\n","The .numpy() method explicitly converts a Tensor to a numpy array\n","[[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]]\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","\n","print(\"\\n========== 연산 ==========\\n\")\n","\n","print(tf.math.add(1, 2))                      # 합\n","print(tf.math.add([1, 2], [3, 4]))            # 합\n","print(tf.math.square(5))                      # 제곱\n","print(tf.math.reduce_sum([1, 2, 3]))          # 전체\n","print(tf.math.square(2) + tf.math.square(3))  # 제곱과 제곱의 합\n","\n","print(\"\\n========== 크기와 데이터 타입 ==========\\n\")\n","\n","x = tf.linalg.matmul([[1]], [[2, 3]])   # 행렬 곱셈\n","print(x)\n","print(x.shape)\n","print(x.dtype)\n","\n","print(\"\\n========== Tensor와 NumPy의 호환성 ==========\\n\")\n","\n","ndarray = np.ones([3, 3])\n","tensor = tf.math.multiply(ndarray, 42)\n","\n","print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n","print(tensor)\n","print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n","print(np.add(tensor, 1))\n","print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n","print(tensor.numpy())\n","\n","\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# 필요 시 텐서를 CPU와 GPU 메모리 사이에서 복사\n","# 연산에 의해 생성된 텐서는 전형적으로 연산이 실행된 장치의 메모리에 의해 실행\n","\n","print(\"\\n========== GPU 가속 ==========\\n\") # 런타임을 GPU로 바꾸고 실행하기\n","\n","x = tf.random.uniform([3, 3])\n","\n","print(\"Is there a GPU available :\", tf.config.list_physical_devices(\"GPU\"))\n","print(\"Is the Tensor on GPU #0 :\", x.device.endswith('GPU:0'))\n"],"metadata":{"id":"LCqP-JTlx1Jj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736921701960,"user_tz":-540,"elapsed":8800,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"232df8ba-7f83-4dd0-f92b-2da8ded00828"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== GPU 가속 ==========\n","\n","Is there a GPU available : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","Is the Tensor on GPU #0 : True\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import time\n","\n","# 명시적인 지침이 제공되지 않으면 TensorFlow는 연산을 실행할 장치를 자동으로 결정하고 필요한 경우 해당 장치에 텐서를 복사\n","# TensorFlow 연산은 tf.device 컨텍스트 관리자를 사용하여 특정 장치에 명시적으로 배치\n","\n","print(\"\\n========== 명시적 장치 배치 ==========\\n\")\n","\n","def time_matmul(x):\n","  start = time.time()                         # 시작 시간을 기록\n","  for loop in range(10):                      # 10번 반복하여 실행\n","    tf.linalg.matmul(x, x)                    # 행렬 곱셈 연산\n","  result = time.time() - start                # 끝난 후 시간을 측정\n","  print(f\"10 loops: {(1000*result):0.2f}ms\")  # 밀리초 단위로 실행 시간 출력\n","\n","print(\"On CPU:\")\n","with tf.device(\"CPU:0\"):                      # CPU에서 실행\n","  x = tf.random.uniform([1000, 1000])         # 1000x1000 크기의 무작위 텐서를 생성\n","  assert x.device.endswith(\"CPU:0\")           # x 텐서가 CPU에 배치되었는지 확인\n","  time_matmul(x)                              # 행렬 곱셈 연산 시간을 측정\n","\n","print(\"On CPU:\")\n","with tf.device(\"CPU:0\"):                      # CPU에서 실행\n","  x = tf.random.uniform([1000, 1000])         # 1000x1000 크기의 무작위 텐서를 생성\n","  assert x.device.endswith(\"CPU:0\")           # x 텐서가 CPU에 배치되었는지 확인\n","  time_matmul(x)                              # 행렬 곱셈 연산 시간을 측정\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hezoVlD7lIDE","executionInfo":{"status":"ok","timestamp":1736921751988,"user_tz":-540,"elapsed":473,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"f6928aca-f4b0-44c0-fe49-aa104d19fa5a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","========== 명시적 장치 배치 ==========\n","\n","On CPU:\n","10 loops: 287.85ms\n","On GPU:\n","10 loops: 111.09ms\n"]}]},{"cell_type":"code","source":["# 데이터세트\n","\n","ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6]) # 결과적으로 ds_tensors는 [1], [2], [3], [4], [5], [6]과 같은 6개의 요소를 갖는 데이터셋이 된다.\n","\n","# CSV 파일 생성\n","import tempfile\n","_, filename = tempfile.mkstemp()\n","\n","with open(filename, 'w') as f:\n","  f.write(\"Line1\\nLine2\\nLine3\")\n","\n","ds_file = tf.data.TextLineDataset(filename) # 지정된 파일을 읽고 각 줄을 텍스트 항목으로 나누어 데이터셋을 생성\n","\n","# 변환 적용\n","\n","ds_tensor = ds_tensors.map(tf.math.square).shuffle(2).batch(2)  # map 함수는 데이터셋의 각 요소에 주어진 함수를 적용한다. tf.math.square는 입력값의 제곱을 계산한다. shuffle(N)은 버퍼 크기를 N으로 지정해, 데이터셋의 요소가 N개씩 임시로 저장되어 섞인 후, 다시 원래 데이터셋에 삽입한다. 데이터셋을 지정된 크기의 배치로 묶는다.\n","ds_file = ds_file.batch(2)                                      # batch를 2로 적용해 Line1과 Line2가 첫번째 배치로 Line3rk 두번째 배치로 묶은다.\n","\n","# 반복\n","\n","print('\\nElements of ds_tensors:')\n","for x in ds_tensors:\n","  print(x)\n","\n","print('\\nElements in ds_file:')\n","for x in ds_file:\n","  print(x)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WwQzuv5HqDQr","executionInfo":{"status":"ok","timestamp":1736924265256,"user_tz":-540,"elapsed":1011,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"fd9e9c1d-4d6e-4e34-edb2-ca3cac9cb5b1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Elements of ds_tensors:\n","tf.Tensor(1, shape=(), dtype=int32)\n","tf.Tensor(2, shape=(), dtype=int32)\n","tf.Tensor(3, shape=(), dtype=int32)\n","tf.Tensor(4, shape=(), dtype=int32)\n","tf.Tensor(5, shape=(), dtype=int32)\n","tf.Tensor(6, shape=(), dtype=int32)\n","\n","Elements in ds_file:\n","tf.Tensor([b'Line1' b'Line2'], shape=(2,), dtype=string)\n","tf.Tensor([b'Line3'], shape=(1,), dtype=string)\n"]}]}]}