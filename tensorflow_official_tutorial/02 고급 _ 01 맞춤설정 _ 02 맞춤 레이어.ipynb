{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEeqsxGi4bUB355pFr8R9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 사용자 정의 층\n","https://www.tensorflow.org/tutorials/customization/custom_layers?hl=ko\n"],"metadata":{"id":"R2P445ekE6iO"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9yzcUL_EfgJ","executionInfo":{"status":"ok","timestamp":1736829276723,"user_tz":-540,"elapsed":296,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"29c13ebc-da40-4a06-fc7f-8ff63cfa1b29"},"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}],"source":["import tensorflow as tf\n","\n","print(tf.config.list_physical_devices('GPU'))\n"]},{"cell_type":"code","source":["# 층 : 유용한 연산자 집합\n","\n","# 레이어 객체 : 파라미터1은 출력 차원(혹은 노드나 뉴런)이고 파라미터2은 출력 채널(예시로 RGB는 3)이다.\n","\n","import tensorflow as tf\n","\n","layer = tf.keras.layers.Dense(100)\n","layer = tf.keras.layers.Dense(10, input_shape=(None, 5))\n","layer(tf.zeros([10, 5]))\n","\n","print(layer.variables)  # 레이어의 학습 가능한 모든 변수들을 리스트 형태로 반환\n","print(f\"레이어의 가중치 : {layer.kernel}\")\n","print(f\"레이어의 편향   : {layer.bias}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E7vozE04F9YG","executionInfo":{"status":"ok","timestamp":1736831338509,"user_tz":-540,"elapsed":285,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"43458392-6aa4-4b82-c841-a8d39b48aa9f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["[<KerasVariable shape=(5, 10), dtype=float32, path=dense_17/kernel>, <KerasVariable shape=(10,), dtype=float32, path=dense_17/bias>]\n","레이어의 가중치 : <KerasVariable shape=(5, 10), dtype=float32, path=dense_17/kernel>\n","레이어의 편향   : <KerasVariable shape=(10,), dtype=float32, path=dense_17/bias>\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# 사용자 정의 층 구현\n","\n","class MyDenseLayer(tf.keras.layers.Layer):\n","\n","    def __init__(self, num_outputs):                  # 모든 입력 독립적 초기화 수행\n","        super(MyDenseLayer, self).__init__()          # 부모 클래스인 tf.keras.layers.Layer의 생성자를 호출해 레이어를 초기화\n","        self.num_outputs = num_outputs                # 레이어가 가질 출력 차원의 크기를 설정\n","\n","    def build(self, input_shape):                     # 입력 텐서의 형상을 통해 나머지 초기화 작업 수행\n","        self.kernel = self.add_weight(                # .add_weight() : 레이어에 학습 가능한 가중치 kernel을 추가\n","            name=\"kernel\",                            # 변수의 이름 지정\n","            shape=(input_shape[-1], self.num_outputs) # shape=(p1,p2) : p1은 입력 차원 수. p2는 출력 차원 수.\n","        )\n","\n","    def call(self, inputs):                           # 순방향 계산 수행\n","        return tf.matmul(inputs, self.kernel)         # 행렬곱셈. inputs의 크기가 (batch_size, input_dim)이고 kernel의 크기가 (input_dim, num_outputs)라면, 결과는 (batch_size, num_outputs) 형태\n","\n","# 클래스 사용\n","layer = MyDenseLayer(10)                                  # 출력 차원 수(뉴런)가 10개인 덴스 레이어 객체 생성\n","print(tf.zeros([10, 5]).shape)                            # 사용할 레이어의 형태 확인\n","_ = layer(tf.zeros([10, 5]))                              # 반환값을 _에 저장하고 해당 코드가 마지막에 있을 때는 반환값 미출력.10행 5열 형태의 텐서를 모든 원소를 0으로 초기화. 추후에 해당 레이어는 inputs (10,5) 크기와 kernel (5,10) 크기로 행렬 곱셉하기 때문에 결과는 (10,10)으로 나온다.\n","print([var.name for var in layer.trainable_variables])    # 학습 가능한 변수 출력\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNQ0noVcJc4H","executionInfo":{"status":"ok","timestamp":1736836518212,"user_tz":-540,"elapsed":289,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"03262fb9-faf9-43df-ae5c-588f6712375f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["(10, 5)\n","['kernel']\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# 모델: 층 구성\n","\n","# 클래스 선언\n","\n","class ResentIdentityBlock(tf.keras.Model):\n","\n","  def __init__(self, kernel_size, filters):\n","    super(ResentIdentityBlock, self).__init__(name='')\n","    filters1, filters2, filters3 = filters\n","    self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n","    self.bn2a = tf.keras.layers.BatchNormalization()\n","    self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n","    self.bn2b = tf.keras.layers.BatchNormalization()\n","    self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n","    self.bn2c = tf.keras.layers.BatchNormalization()\n","\n","  def call(self, input_tensor, training=False):\n","    if len(input_tensor.shape) == 3: input_tensor = tf.expand_dims(input_tensor, axis=-1)  # 입력 텐서 차원 확인 후, 채널 차원 추가\n","    x = self.conv2a(input_tensor)\n","    x = self.bn2a(x, training=training)\n","    x = tf.nn.relu(x)\n","    x = self.conv2b(x)\n","    x = self.bn2b(x, training=training)\n","    x = tf.nn.relu(x)\n","    x = self.conv2c(x)\n","    x = self.bn2c(x, training=training)\n","    x += input_tensor\n","    return tf.nn.relu(x)\n","\n","# 클래스 사용\n","\n","block = ResentIdentityBlock(1, [1, 2, 3])\n","_ = block(tf.zeros([1, 2, 3, 3]))  # 입력 텐서 크기: (배치 크기 1, 높이 2, 너비 3, 채널 3)\n","print(block.layers)\n","print(block.variables)\n","print(len(block.variables))\n","block.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"id":"IiUjx8wOZRX5","executionInfo":{"status":"ok","timestamp":1736838997504,"user_tz":-540,"elapsed":260,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"07529784-a90a-42db-8995-bca0846d3391"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["[<Conv2D name=conv2d_24, built=True>, <BatchNormalization name=batch_normalization_22, built=True>, <Conv2D name=conv2d_25, built=True>, <BatchNormalization name=batch_normalization_23, built=True>, <Conv2D name=conv2d_26, built=True>, <BatchNormalization name=batch_normalization_24, built=True>]\n","[<KerasVariable shape=(1, 1, 3, 1), dtype=float32, path=conv2d_24/kernel>, <KerasVariable shape=(1,), dtype=float32, path=conv2d_24/bias>, <KerasVariable shape=(1,), dtype=float32, path=batch_normalization_22/gamma>, <KerasVariable shape=(1,), dtype=float32, path=batch_normalization_22/beta>, <KerasVariable shape=(1,), dtype=float32, path=batch_normalization_22/moving_mean>, <KerasVariable shape=(1,), dtype=float32, path=batch_normalization_22/moving_variance>, <KerasVariable shape=(1, 1, 1, 2), dtype=float32, path=conv2d_25/kernel>, <KerasVariable shape=(2,), dtype=float32, path=conv2d_25/bias>, <KerasVariable shape=(2,), dtype=float32, path=batch_normalization_23/gamma>, <KerasVariable shape=(2,), dtype=float32, path=batch_normalization_23/beta>, <KerasVariable shape=(2,), dtype=float32, path=batch_normalization_23/moving_mean>, <KerasVariable shape=(2,), dtype=float32, path=batch_normalization_23/moving_variance>, <KerasVariable shape=(1, 1, 2, 3), dtype=float32, path=conv2d_26/kernel>, <KerasVariable shape=(3,), dtype=float32, path=conv2d_26/bias>, <KerasVariable shape=(3,), dtype=float32, path=batch_normalization_24/gamma>, <KerasVariable shape=(3,), dtype=float32, path=batch_normalization_24/beta>, <KerasVariable shape=(3,), dtype=float32, path=batch_normalization_24/moving_mean>, <KerasVariable shape=(3,), dtype=float32, path=batch_normalization_24/moving_variance>]\n","18\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │               \u001b[38;5;34m4\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_22               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │               \u001b[38;5;34m4\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m)                │               \u001b[38;5;34m4\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_23               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m2\u001b[0m)                │               \u001b[38;5;34m8\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m)                │               \u001b[38;5;34m9\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_24               │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m)                │              \u001b[38;5;34m12\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_22               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_23               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_24               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41\u001b[0m (164.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> (164.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12\u001b[0m (48.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> (48.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# 단순하게 층을 순서대로 하나씩 호출\n","\n","import tensorflow as tf\n","\n","my_seq = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(1, (1, 1), input_shape=(None, None, 3)),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(2, 1, padding='same'),\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Conv2D(3, (1, 1)),\n","    tf.keras.layers.BatchNormalization()\n","])\n","\n","my_seq(tf.zeros([1, 2, 3, 3]))\n","\n","my_seq.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"rUe1K-EprBVW","executionInfo":{"status":"ok","timestamp":1736839013017,"user_tz":-540,"elapsed":269,"user":{"displayName":"신유진","userId":"04332250286007770498"}},"outputId":"a2425621-dd4e-4dbc-860f-bcd5c0c08966"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │               \u001b[38;5;34m4\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_25               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │               \u001b[38;5;34m4\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │               \u001b[38;5;34m4\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_26               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)       │               \u001b[38;5;34m8\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m9\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │              \u001b[38;5;34m12\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_25               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_26               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41\u001b[0m (164.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41</span> (164.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m12\u001b[0m (48.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> (48.00 B)\n","</pre>\n"]},"metadata":{}}]}]}