{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOG6TMvZ38Ky9xomgFWgdRl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"56tyDcUkwFJ5","outputId":"25834795-a024-4808-d4a0-e18eee39fd7f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739419491848,"user_tz":-540,"elapsed":14832,"user":{"displayName":"신유진","userId":"04332250286007770498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["기간 경과율을 계산합니다.\n","\n","- 전체 일수 : 8\n","- 잔여 일수 : 2\n","\n","기간 경과율: 75.0%\n"]}],"source":["# 전체 일수와 잔여 일수\n","print(\"기간 경과율을 계산합니다.\\n\")\n","input_total_days = int(input(\"- 전체 일수 : \"))\n","input_remaining_days = int(input(\"- 잔여 일수 : \"))\n","\n","# 기간 경과율 계산\n","elapsed_percentage = ((input_total_days - input_remaining_days) / input_total_days) * 100\n","\n","# 결과 출력\n","print(f\"\\n기간 경과율: {elapsed_percentage}%\")\n"]},{"cell_type":"code","source":["# 미니배치 학습\n","#  - 전체 훈련 데이터를 작은 미니 배치 (mini-batch)로 나눠 각각의 미니배치에 대해 모델을 학습시키는 방법이다.\n","#  - 전체 데이터를 한번에 처리하는 것보다 효율적이며, 메모리 사용량을 줄이고 계산 속도를 높일 수 있다.\n","\n","# 미니배치 학습의 예시\n","# https://allensdatablog.tistory.com/entry/Mini-batch-%ED%95%99%EC%8A%B5-%EB%8C%80%EC%9A%A9%EB%9F%89-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%9C%BC%EB%A1%9C-%EB%8B%A4%EB%A3%A8%EA%B8%B0\n","\n","# - 예시 : 이미지 분류\n","# - 배경 : 대용량의 이미지 데이터셋을 사용해 이미지 분류 모델을 학습함.\n","# - 방법 : 미니배치 학습을 사용해 모델을 효율적으로 학습시킴.\n","\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# MNIST 데이터셋 로드\n","mnist_data = mnist.load_data()\n","print(mnist_data)\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# 데이터 전처리\n","x_train = x_train.reshape(-1, 28*28) / 255.0\n","x_test = x_test.reshape(-1, 28*28) / 255.0\n","print(f\"x_train.shape : {x_train.shape}\")\n","print(f\"x_test.shape : {x_test.shape}\")\n","\n","# 모델 정의\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(784,)),\n","    Dense(64, activation='relu'),\n","    Dense(10, activation='softmax')\n","])\n","\n","# 모델 컴파일\n","model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# 미니배치 학습 수행 : 전체 훈련 데이터에서 20%는 검증으로 떼고 80% 중에서 64개씩 미니배치로 묶어 10회 반복 훈련하기\n","batch_size = 64\n","epochs = 10\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n"],"metadata":{"id":"0pcTrQZVwJ_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 연산\n","\n","import tensorflow as tf\n","\n","c1 = tf.constant([[1, 2], [3, 4]])\n","c2 = tf.constant([[4, 7], [-1, 0]])\n","c3 = tf.constant(10)\n","c4 = tf.constant(7)\n","e = tf.constant([[1, 0], [0, 1]])\n","v1 = tf.Variable([[10, 9], [8, 7]])\n","v2 = tf.Variable([[3, 6], [5, -1]])\n","\n","print(tf.add(c1, c2))\n","print(tf.add_n([c1, c2, c1]))\n","print(tf.add(c1, v1))\n","print(tf.subtract(v1, v2))\n","print(tf.multiply(c1, e))\n","print(tf.matmul(c1, e))\n","print(tf.divide(c3, c4))\n"],"metadata":{"id":"m0nwxjyuwOxP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 리포트 작성 모델 코드\n","\n","# python-docx 라이브러리 설치\n","# !pip install python-docx\n","\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from docx import Document\n","\n","# 데이터 생성\n","X = np.linspace(0, 10, 100)\n","y = 2 * X + 1 + np.random.normal(0, 1, X.shape)\n","data = pd.DataFrame({\"X\": X, \"y\": y})\n","\n","# 그래프 생성\n","plt.figure(figsize=(8, 6))\n","plt.scatter(X, y, color=\"blue\", label=\"Observed Data\")\n","plt.title(\"Generated Data\")\n","plt.xlabel(\"X\")\n","plt.ylabel(\"y\")\n","plt.legend()\n","plt.savefig(\"data_plot.png\")\n","plt.close()\n","\n","# 선형 회귀 모델\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1, input_shape=(1,))\n","])\n","\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# 모델 훈련\n","history = model.fit(X, y, epochs=100, verbose=0)\n","\n","# 손실 값 확인 (history 객체에 loss 기록이 있는지 확인)\n","if 'loss' in history.history:\n","    loss_value = history.history['loss'][-1]\n","else:\n","    loss_value = \"손실 값 기록 없음\"\n","\n","# 예측\n","y_pred = model.predict(X)\n","\n","# 리포트 텍스트\n","report_text = f\"\"\"\n","리포트 제목: 선형 회귀 모델 분석 결과\n","\n","모델 설명: 이 모델은 X와 y 사이의 선형 관계를 예측하는 선형 회귀 모델입니다.\n","학습된 모델은 y = 2X + 1의 관계를 잘 근사하며, 약간의 노이즈를 포함하고 있습니다.\n","\n","모델 성능:\n","- 손실 함수 값: {loss_value}\n","\n","예측 결과:\n","- 첫 5개의 예측 값은 다음과 같습니다: {y_pred[:5].flatten()}\n","\n","그래프:\n","위의 그래프는 모델이 학습한 데이터와 예측 결과를 시각화한 것입니다.\n","\"\"\"\n","\n","# 리포트 텍스트 파일로 저장\n","with open(\"report.txt\", \"w\") as f:\n","    f.write(report_text)\n","\n","# 워드 리포트 생성\n","doc = Document()\n","doc.add_heading('선형 회귀 모델 분석 리포트', 0)\n","doc.add_paragraph(report_text)\n","doc.add_picture('data_plot.png')\n","\n","# 최종 리포트 저장\n","doc.save('final_report.docx')\n"],"metadata":{"id":"7QOn_ld_wdPv"},"execution_count":null,"outputs":[]}]}